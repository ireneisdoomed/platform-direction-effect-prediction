{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "from pathlib import Path\n",
    "from pyspark.sql import DataFrame, SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .master('local[*]') \\\n",
    "        .config(\"spark.driver.memory\", \"15g\") \\\n",
    "        .appName('spark') \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful snippets for the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_null_columns(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    This function drops all columns which only contain null values.\n",
    "    \"\"\"\n",
    "    df_count = df.count()\n",
    "    null_counts = df.select([F.count(F.when(F.col(c).isNull(), c)).alias(c) for c in df.columns]).collect()[0].asDict()\n",
    "    to_drop = [k for k, v in null_counts.items() if v == df_count]\n",
    "    df = df.drop(*to_drop)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_evidence(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    This function groups the evidence on the association level and returns a dataframe with the aggregated values of the direction of effect.\n",
    "    \"\"\"\n",
    "    return df.groupBy('targetId', 'diseaseId', 'datasourceId').agg(\n",
    "        F.size(F.collect_list('effectDirection_down')).alias('effectDirection_down'),\n",
    "        F.size(F.collect_list('effectDirection_up')).alias('effectDirection_up'),\n",
    "        F.size(F.collect_list('effectSize_down')).alias('effectSize_down'),\n",
    "        F.size(F.collect_list('effectSize_up')).alias('effectSize_up'),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['EFO_0005189', 'EFO_0008080', 'EFO_0008167', 'EFO_0008181', 'EFO_0010586']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantitative_traits = (\n",
    "    # EFO IDs that are under measurement\n",
    "    spark.read.parquet('/Users/irene/Documents/dev/pyspark/22.06.2/diseases')\n",
    "    .filter(F.array_contains(F.col('therapeuticAreas'), 'EFO_0001444'))\n",
    "    .select(F.col('id').alias('diseaseId')).distinct()\n",
    "    .toPandas()['diseaseId'].to_list()\n",
    ")\n",
    "\n",
    "quantitative_traits[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Known Drugs: Gold standard\n",
    "\n",
    "Direction of effect comes from the mechanism of action of the drug that modulates the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lof_moas = [\n",
    "    'AGONIST',\n",
    "    'POSITIVE MODULATOR',\n",
    "    'OPENER',\n",
    "    'PARTIAL AGONIST',\n",
    "    'ACTIVATOR',\n",
    "    'STABILISER',\n",
    "    'VACCINE ANTIGEN',\n",
    "    'RELEASING AGENT',\n",
    "    'POSITIVE ALLOSTERIC MODULATOR',\n",
    "]\n",
    "\n",
    "gof_moas = [\n",
    "    'INHIBITOR',\n",
    "    'ANTAGONIST',\n",
    "    'BLOCKER',\n",
    "    'NEGATIVE ALLOSTERIC MODULATOR',\n",
    "    'HYDROLYTIC ENZYME',\n",
    "    'RNAI INHIBITOR',\n",
    "    'PROTEOLYTIC ENZYME',\n",
    "    'NEGATIVE MODULATOR',\n",
    "    'DISRUPTING AGENT',\n",
    "    'ANTISENSE INHIBITOR',\n",
    "    'DEGRADER',\n",
    "    'INVERSE AGONIST',\n",
    "    'ALLOSTERIC ANTAGONIST',\n",
    "    'SEQUESTERING AGENT',\n",
    "    'CHELATING AGENT',\n",
    "    'OXIDATIVE ENZYME',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/07/12 09:31:25 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 11:==============>                                           (2 + 6) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------\n",
      " targetId             | ENSG00000007314 \n",
      " diseaseId            | EFO_0000612     \n",
      " datasourceId         | chembl          \n",
      " effectDirection_down | 0               \n",
      " effectDirection_up   | 5               \n",
      " effectSize_down      | 0               \n",
      " effectSize_up        | 5               \n",
      "-RECORD 1-------------------------------\n",
      " targetId             | ENSG00000007314 \n",
      " diseaseId            | EFO_1000781     \n",
      " datasourceId         | chembl          \n",
      " effectDirection_down | 0               \n",
      " effectDirection_up   | 1               \n",
      " effectSize_down      | 0               \n",
      " effectSize_up        | 1               \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "chembl = (\n",
    "    drop_null_columns(spark.read.parquet('/Users/irene/Documents/dev/pyspark/22.06.2/evidence/sourceId=chembl'))\n",
    "    .join(\n",
    "        spark.read.parquet('/Users/irene/Documents/dev/pyspark/22.06.2/mechanismOfAction')\n",
    "        .select(F.explode('chemblIds').alias('drugId'), 'actionType').distinct(),\n",
    "        on='drugId', how='inner'\n",
    "    )\n",
    "    .filter((F.col('actionType').isin(lof_moas)) | (F.col('actionType').isin(gof_moas)))\n",
    "    .withColumn('effectDirection_up', F.when(F.col('actionType').isin(gof_moas), F.lit(True)))\n",
    "    .withColumn('effectDirection_down', F.when(F.col('actionType').isin(lof_moas), F.lit(True)))\n",
    "    .withColumn('effectSize_up', F.lit(True))\n",
    "    .withColumn('effectSize_down', F.lit(None))\n",
    "    .transform(aggregate_evidence)\n",
    ")\n",
    "\n",
    "chembl.show(2, False, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gene2Phenotype\n",
    "\n",
    "Directionality:\n",
    "- absent_gene_product: SO_0002317\n",
    "- increased_gene_product_level: SO_0002315"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------\n",
      " targetId             | ENSG00000163093 \n",
      " diseaseId            | EFO_0009025     \n",
      " datasourceId         | gene2phenotype  \n",
      " effectDirection_down | 2               \n",
      " effectDirection_up   | 0               \n",
      " effectSize_down      | 0               \n",
      " effectSize_up        | 2               \n",
      "-RECORD 1-------------------------------\n",
      " targetId             | ENSG00000186326 \n",
      " diseaseId            | MONDO_0012033   \n",
      " datasourceId         | gene2phenotype  \n",
      " effectDirection_down | 1               \n",
      " effectDirection_up   | 0               \n",
      " effectSize_down      | 0               \n",
      " effectSize_up        | 1               \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "g2p = (\n",
    "    drop_null_columns(spark.read.parquet('/Users/irene/Documents/dev/pyspark/22.06.2/evidence/sourceId=gene2phenotype'))\n",
    "    .withColumn(\n",
    "        'effectDirection_down',\n",
    "        F.when(F.col('variantFunctionalConsequenceId') == 'SO_0002317', F.lit(True))\n",
    "    )\n",
    "    .withColumn('effectDirection_up', F.when(F.col('variantFunctionalConsequenceId') == 'SO_0002315', F.lit(True)))\n",
    "    .withColumn('effectSize_up', F.lit(True))\n",
    "    .withColumn('effectSize_down', F.lit(None))\n",
    "    .filter(F.col('effectDirection_up').isNotNull() | F.col('effectDirection_down').isNotNull())\n",
    "    .transform(aggregate_evidence)\n",
    "\n",
    ")\n",
    "\n",
    "g2p.show(2, False, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orphanet\n",
    "\n",
    "Directionality:\n",
    "- loss_of_function_variant: SO_0002054\n",
    "- gain_of_function_variant: SO_0002053"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------\n",
      " targetId             | ENSG00000130294 \n",
      " diseaseId            | MONDO_0019941   \n",
      " datasourceId         | orphanet        \n",
      " effectDirection_down | 1               \n",
      " effectDirection_up   | 0               \n",
      " effectSize_down      | 0               \n",
      " effectSize_up        | 1               \n",
      "-RECORD 1-------------------------------\n",
      " targetId             | ENSG00000143520 \n",
      " diseaseId            | MONDO_0014555   \n",
      " datasourceId         | orphanet        \n",
      " effectDirection_down | 1               \n",
      " effectDirection_up   | 0               \n",
      " effectSize_down      | 0               \n",
      " effectSize_up        | 1               \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "orphanet = (\n",
    "    drop_null_columns(spark.read.parquet('/Users/irene/Documents/dev/pyspark/22.06.2/evidence/sourceId=orphanet'))\n",
    "    .withColumn(\n",
    "        'effectDirection_down',\n",
    "        F.when(F.col('variantFunctionalConsequenceId') == 'SO_0002054', F.lit(True))\n",
    "    )\n",
    "    .withColumn('effectDirection_up', F.when(F.col('variantFunctionalConsequenceId') == 'SO_0002053', F.lit(True)))\n",
    "    .withColumn('effectSize_up', F.lit(True))\n",
    "    .withColumn('effectSize_down', F.lit(None))\n",
    "    .filter(F.col('effectDirection_up').isNotNull() | F.col('effectDirection_down').isNotNull())\n",
    "    .transform(aggregate_evidence)\n",
    ")\n",
    "\n",
    "orphanet.show(2,False,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gene burden\n",
    "\n",
    "- Models that consider PTVs are always LoF\n",
    "- Effect size come from the betas/ORs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 32:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------\n",
      " targetId             | ENSG00000012048 \n",
      " diseaseId            | EFO_0000305     \n",
      " datasourceId         | gene_burden     \n",
      " effectDirection_down | 6               \n",
      " effectDirection_up   | 0               \n",
      " effectSize_down      | 1               \n",
      " effectSize_up        | 5               \n",
      "-RECORD 1-------------------------------\n",
      " targetId             | ENSG00000105610 \n",
      " diseaseId            | EFO_0004526     \n",
      " datasourceId         | gene_burden     \n",
      " effectDirection_down | 14              \n",
      " effectDirection_up   | 0               \n",
      " effectSize_down      | 14              \n",
      " effectSize_up        | 0               \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "lof_models = [\n",
    "    'ptv5pcnt',\n",
    "    'ptv',\n",
    "    'ptvraredmg',\n",
    "    'pLoF',\n",
    "    'MLOF-VT',\n",
    "    'MLOF-MB',\n",
    "    'LOF-Burden',\n",
    "    'LOF-VT',\n",
    "    'ADD-WGR-FIRTH_M1.singleton',\n",
    "    'ADD-WGR-FIRTH_M1.01',\n",
    "    'ADD-WGR-FIRTH_M1.001',\n",
    "    'ADD-WGR-FIRTH_M1.1',\n",
    "    'ADD-WGR-FIRTH_M1.0001',\n",
    "]\n",
    "\n",
    "burden = (\n",
    "    drop_null_columns(spark.read.parquet('/Users/irene/Documents/dev/pyspark/22.06.2/evidence/sourceId=gene_burden'))\n",
    "    .filter(F.col('statisticalMethod').isin(lof_models))\n",
    "    .withColumn('effectDirection_down', F.lit(True))\n",
    "    .withColumn('effectDirection_up', F.lit(None))\n",
    "    .withColumn('effectSize_down', F.when((F.col('beta') < 0) | (F.col('oddsRatio') < 1), F.lit(True)))\n",
    "    .withColumn('effectSize_up', F.when((F.col('beta') > 0) | (F.col('oddsRatio') > 1), F.lit(True)))\n",
    "    .transform(aggregate_evidence)\n",
    ")\n",
    "\n",
    "burden.show(2, False, True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  GWAS of coding variants (Genetics)\n",
    "\n",
    "- Models that consider PTVs are always LoF\n",
    "- Effect size come from the betas/ORs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lof_consequences = [\n",
    "    'SO_0001589', # frameshift\n",
    "    'SO_0002012', # start_lost\n",
    "    'SO_0001587', # stop_gained\n",
    "    'SO_0001818', # protein altering variant\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0----------------------------------\n",
      " targetId             | ENSG00000205045    \n",
      " diseaseId            | EFO_0004833        \n",
      " datasourceId         | ot_genetics_portal \n",
      " effectDirection_down | 2                  \n",
      " effectDirection_up   | 0                  \n",
      " effectSize_down      | 2                  \n",
      " effectSize_up        | 0                  \n",
      "-RECORD 1----------------------------------\n",
      " targetId             | ENSG00000176920    \n",
      " diseaseId            | EFO_0005760        \n",
      " datasourceId         | ot_genetics_portal \n",
      " effectDirection_down | 1                  \n",
      " effectDirection_up   | 0                  \n",
      " effectSize_down      | 0                  \n",
      " effectSize_up        | 1                  \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "ot_genetics = (\n",
    "    drop_null_columns(spark.read.parquet('/Users/irene/Documents/dev/pyspark/22.06.2/evidence/sourceId=ot_genetics_portal'))\n",
    "    .filter(F.col('variantFunctionalConsequenceId').isin(lof_consequences))\n",
    "    .withColumn('effectDirection_down', F.lit(True))\n",
    "    .withColumn('effectDirection_up', F.lit(None))\n",
    "    .withColumn('effectSize_down', F.when((F.col('beta') < 0) | (F.col('oddsRatio') < 1), F.lit(True)))\n",
    "    .withColumn('effectSize_up', F.when((F.col('beta') > 0) | (F.col('oddsRatio') > 1), F.lit(True)))\n",
    "    .transform(aggregate_evidence)\n",
    ")\n",
    "\n",
    "ot_genetics.show(2, False, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ClinVar\n",
    "\n",
    "- LoF variants are considered\n",
    "- Clinical significance addresses the size of the effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "significances = [\n",
    "    'pathogenic',\n",
    "    'likely pathogenic',\n",
    "    'risk factor',\n",
    "    'protective',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 50:========================================>               (10 + 4) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------\n",
      " targetId             | ENSG00000018236 \n",
      " diseaseId            | MONDO_0012929   \n",
      " datasourceId         | clinvar         \n",
      " effectDirection_down | 9               \n",
      " effectDirection_up   | 0               \n",
      " effectSize_down      | 0               \n",
      " effectSize_up        | 9               \n",
      "-RECORD 1-------------------------------\n",
      " targetId             | ENSG00000049860 \n",
      " diseaseId            | MONDO_0010006   \n",
      " datasourceId         | clinvar         \n",
      " effectDirection_down | 79              \n",
      " effectDirection_up   | 0               \n",
      " effectSize_down      | 0               \n",
      " effectSize_up        | 79              \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "clinvar = (\n",
    "    drop_null_columns(spark.read.parquet('/Users/irene/Documents/dev/pyspark/22.06.2/evidence/sourceId=eva*'))\n",
    "    .withColumn('datasourceId', F.lit('clinvar'))\n",
    "    .withColumn('significance', F.explode('clinicalSignificances'))\n",
    "    .filter(F.col('significance').isin(significances))\n",
    "    .filter(F.col('variantFunctionalConsequenceId').isin(lof_consequences))\n",
    "    .withColumn('effectDirection_down', F.lit(True))\n",
    "    .withColumn('effectDirection_up', F.lit(None))\n",
    "    .withColumn('effectSize_down', F.when(F.col('significance') == 'protective', F.lit(True)))\n",
    "    .withColumn('effectSize_up', F.when(F.col('significance') != 'protective', F.lit(True)))\n",
    "    .transform(aggregate_evidence)\n",
    ")\n",
    "\n",
    "clinvar.show(2, False, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mouse models\n",
    "\n",
    "All the genotypes refer to KO models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 57:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------\n",
      " targetId             | ENSG00000001461 \n",
      " diseaseId            | EFO_1001451     \n",
      " datasourceId         | impc            \n",
      " effectDirection_down | 1               \n",
      " effectDirection_up   | 0               \n",
      " effectSize_down      | 0               \n",
      " effectSize_up        | 1               \n",
      "-RECORD 1-------------------------------\n",
      " targetId             | ENSG00000001617 \n",
      " diseaseId            | MONDO_0009141   \n",
      " datasourceId         | impc            \n",
      " effectDirection_down | 1               \n",
      " effectDirection_up   | 0               \n",
      " effectSize_down      | 0               \n",
      " effectSize_up        | 1               \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "impc = (\n",
    "    drop_null_columns(spark.read.parquet('/Users/irene/Documents/dev/pyspark/22.06.2/evidence/sourceId=impc'))\n",
    "    .withColumn('effectDirection_down', F.lit(True))\n",
    "    .withColumn('effectDirection_up', F.lit(None))\n",
    "    .withColumn('effectSize_up', F.lit(True))\n",
    "    .withColumn('effectSize_down', F.lit(None))\n",
    "    .transform(aggregate_evidence)\n",
    ")\n",
    "\n",
    "impc.show(2, False, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differential expression\n",
    "\n",
    "- All experiments are disease vs control\n",
    "    - Positive fold change: increase of expression\n",
    "    - Negative fold change: decrease of expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 64:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0--------------------------------\n",
      " targetId             | ENSG00000003137  \n",
      " diseaseId            | EFO_0003096      \n",
      " datasourceId         | expression_atlas \n",
      " effectDirection_down | 1                \n",
      " effectDirection_up   | 0                \n",
      " effectSize_down      | 0                \n",
      " effectSize_up        | 1                \n",
      "-RECORD 1--------------------------------\n",
      " targetId             | ENSG00000004777  \n",
      " diseaseId            | EFO_0000676      \n",
      " datasourceId         | expression_atlas \n",
      " effectDirection_down | 1                \n",
      " effectDirection_up   | 0                \n",
      " effectSize_down      | 0                \n",
      " effectSize_up        | 1                \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "expression = (\n",
    "    drop_null_columns(spark.read.parquet('/Users/irene/Documents/dev/pyspark/22.06.2/evidence/sourceId=expression_atlas'))\n",
    "    .withColumn('effectDirection_down', F.when(F.col('log2FoldChangeValue') < 0, F.lit(True)))\n",
    "    .withColumn('effectDirection_up', F.when(F.col('log2FoldChangeValue') > 0, F.lit(True)))\n",
    "    .withColumn('effectSize_down', F.lit(None))\n",
    "    .withColumn('effectSize_up', F.lit(True))\n",
    "    .transform(aggregate_evidence)\n",
    ")\n",
    "\n",
    "expression.show(2, False, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Score\n",
    "\n",
    "Synthetic lethality -> all LoF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 71:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------\n",
      " targetId             | ENSG00000166595 \n",
      " diseaseId            | EFO_0001378     \n",
      " datasourceId         | crispr          \n",
      " effectDirection_down | 1               \n",
      " effectDirection_up   | 0               \n",
      " effectSize_down      | 0               \n",
      " effectSize_up        | 1               \n",
      "-RECORD 1-------------------------------\n",
      " targetId             | ENSG00000197713 \n",
      " diseaseId            | EFO_0001075     \n",
      " datasourceId         | crispr          \n",
      " effectDirection_down | 1               \n",
      " effectDirection_up   | 0               \n",
      " effectSize_down      | 0               \n",
      " effectSize_up        | 1               \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "crispr = (\n",
    "    drop_null_columns(spark.read.parquet('/Users/irene/Documents/dev/pyspark/22.06.2/evidence/sourceId=crispr'))\n",
    "    .withColumn('effectDirection_down', F.lit(True))\n",
    "    .withColumn('effectDirection_up', F.lit(None))\n",
    "    .withColumn('effectSize_up', F.lit(True))\n",
    "    .withColumn('effectSize_down', F.lit(None))\n",
    "    .transform(aggregate_evidence)\n",
    ")\n",
    "\n",
    "crispr.show(2, False, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    chembl,\n",
    "    g2p,\n",
    "    orphanet,\n",
    "    burden,\n",
    "    ot_genetics,\n",
    "    clinvar,\n",
    "    impc,\n",
    "    expression,\n",
    "    crispr,\n",
    "    # oncology,\n",
    "    # coloc,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = reduce(DataFrame.unionByName, datasets).repartition(20).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "cwd = Path.cwd().parent\n",
    "\n",
    "all_data.write.parquet(str(cwd / 'outputs' / 'data_harmonisation'), mode='overwrite')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f4b6dc36c032161cfa2dcc93f31fcb0bfb11bc6fea6f0772b15a0710e4778680"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
