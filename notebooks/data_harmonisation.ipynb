{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "from pathlib import Path\n",
    "from pyspark.sql import DataFrame, SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .master('local[*]') \\\n",
    "        .config(\"spark.driver.memory\", \"15g\") \\\n",
    "        .config(\"spark.ui.showConsoleProgress\", \"false\") \\\n",
    "        .appName('spark') \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful snippets for the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_null_columns(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Drops all columns which only contain null values.\n",
    "    \"\"\"\n",
    "    df_count = df.count()\n",
    "    null_counts = df.select([F.count(F.when(F.col(c).isNull(), c)).alias(c) for c in df.columns]).collect()[0].asDict()\n",
    "    to_drop = [k for k, v in null_counts.items() if v == df_count]\n",
    "    df = df.drop(*to_drop)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_evidence(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Groups the evidence on the association level and returns a dataframe with the aggregated values of the direction of effect.\n",
    "    \"\"\"\n",
    "    return df.groupBy('targetId', 'diseaseId', 'datasourceId').agg(\n",
    "        F.size(F.collect_list('effectDirection_down')).alias('effectDirection_down'),\n",
    "        F.size(F.collect_list('effectDirection_up')).alias('effectDirection_up'),\n",
    "        F.size(F.collect_list('effectSize_down')).alias('effectSize_down'),\n",
    "        F.size(F.collect_list('effectSize_up')).alias('effectSize_up'),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(df: DataFrame, all: bool = False) -> None:\n",
    "    \"\"\"\n",
    "    Calculates overall counts of the direction of effect dataset.\n",
    "    When all is set to True, the df is aggregated and counts are calculated for all evidence.\n",
    "    \"\"\"\n",
    "    \n",
    "    source_name = df.select('datasourceId').distinct().collect()[0][0]\n",
    "    total = df.select('targetId', 'diseaseId').distinct().count()\n",
    "    if all:\n",
    "        source_name = 'all'\n",
    "        df = df.groupBy('targetId', 'diseaseId').agg(\n",
    "            *[\n",
    "                F.aggregate(F.collect_list(col), F.lit(0), lambda acc, x: acc + x).alias(col)\n",
    "                for col in g2p.columns\n",
    "                if col not in ['diseaseId', 'targetId', 'datasourceId']\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    direction_discrepancies = (\n",
    "        df.filter((F.col('effectDirection_down') > 0) & (F.col('effectDirection_up') > 0))\n",
    "        .count()\n",
    "    )\n",
    "    size_discrepancies = (\n",
    "        df.filter((F.col('effectSize_down') > 0) & (F.col('effectSize_up') > 0))\n",
    "        .count()\n",
    "    )\n",
    "\n",
    "    print(f'STATS for {source_name}')\n",
    "    print(f'... {total} total associations.')\n",
    "    print(\n",
    "        f'... {direction_discrepancies} associations with discrepant direction ({direction_discrepancies/total*100:.2f}%).'\n",
    "    )\n",
    "    print(f'... {size_discrepancies} associations with discrepant size ({size_discrepancies/total*100:.2f}%). \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EFO_0005189', 'EFO_0008080', 'EFO_0008167', 'EFO_0008181', 'EFO_0010586']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantitative_traits = (\n",
    "    # EFO IDs that are under measurement\n",
    "    spark.read.parquet('/Users/irene/Documents/dev/pyspark/22.06.2/diseases')\n",
    "    .filter(F.array_contains(F.col('therapeuticAreas'), 'EFO_0001444'))\n",
    "    .select(F.col('id').alias('diseaseId')).distinct()\n",
    "    .toPandas()['diseaseId'].to_list()\n",
    ")\n",
    "\n",
    "quantitative_traits[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Known Drugs: Gold standard\n",
    "\n",
    "Direction of effect comes from the mechanism of action of the drug that modulates the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lof_moas = [\n",
    "    'AGONIST',\n",
    "    'POSITIVE MODULATOR',\n",
    "    'OPENER',\n",
    "    'PARTIAL AGONIST',\n",
    "    'ACTIVATOR',\n",
    "    'STABILISER',\n",
    "    'VACCINE ANTIGEN',\n",
    "    'RELEASING AGENT',\n",
    "    'POSITIVE ALLOSTERIC MODULATOR',\n",
    "]\n",
    "\n",
    "gof_moas = [\n",
    "    'INHIBITOR',\n",
    "    'ANTAGONIST',\n",
    "    'BLOCKER',\n",
    "    'NEGATIVE ALLOSTERIC MODULATOR',\n",
    "    'HYDROLYTIC ENZYME',\n",
    "    'RNAI INHIBITOR',\n",
    "    'PROTEOLYTIC ENZYME',\n",
    "    'NEGATIVE MODULATOR',\n",
    "    'DISRUPTING AGENT',\n",
    "    'ANTISENSE INHIBITOR',\n",
    "    'DEGRADER',\n",
    "    'INVERSE AGONIST',\n",
    "    'ALLOSTERIC ANTAGONIST',\n",
    "    'SEQUESTERING AGENT',\n",
    "    'CHELATING AGENT',\n",
    "    'OXIDATIVE ENZYME',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/07/12 11:54:01 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------\n",
      " targetId             | ENSG00000007314 \n",
      " diseaseId            | EFO_0000612     \n",
      " datasourceId         | chembl          \n",
      " effectDirection_down | 0               \n",
      " effectDirection_up   | 5               \n",
      " effectSize_down      | 0               \n",
      " effectSize_up        | 5               \n",
      "-RECORD 1-------------------------------\n",
      " targetId             | ENSG00000007314 \n",
      " diseaseId            | EFO_1000781     \n",
      " datasourceId         | chembl          \n",
      " effectDirection_down | 0               \n",
      " effectDirection_up   | 1               \n",
      " effectSize_down      | 0               \n",
      " effectSize_up        | 1               \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chembl = (\n",
    "    drop_null_columns(spark.read.parquet('/Users/irene/Documents/dev/pyspark/22.06.2/evidence/sourceId=chembl'))\n",
    "    .join(\n",
    "        spark.read.parquet('/Users/irene/Documents/dev/pyspark/22.06.2/mechanismOfAction')\n",
    "        .select(F.explode('chemblIds').alias('drugId'), 'actionType').distinct(),\n",
    "        on='drugId', how='inner'\n",
    "    )\n",
    "    .filter((F.col('actionType').isin(lof_moas)) | (F.col('actionType').isin(gof_moas)))\n",
    "    .withColumn('effectDirection_up', F.when(F.col('actionType').isin(gof_moas), F.lit(True)))\n",
    "    .withColumn('effectDirection_down', F.when(F.col('actionType').isin(lof_moas), F.lit(True)))\n",
    "    .withColumn('effectSize_up', F.lit(True))\n",
    "    .withColumn('effectSize_down', F.lit(None))\n",
    "    .transform(aggregate_evidence)\n",
    ")\n",
    "\n",
    "chembl.show(2, False, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gene2Phenotype\n",
    "\n",
    "Directionality:\n",
    "- absent_gene_product: SO_0002317\n",
    "- increased_gene_product_level: SO_0002315"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------\n",
      " targetId             | ENSG00000163093 \n",
      " diseaseId            | EFO_0009025     \n",
      " datasourceId         | gene2phenotype  \n",
      " effectDirection_down | 2               \n",
      " effectDirection_up   | 0               \n",
      " effectSize_down      | 0               \n",
      " effectSize_up        | 2               \n",
      "-RECORD 1-------------------------------\n",
      " targetId             | ENSG00000186326 \n",
      " diseaseId            | MONDO_0012033   \n",
      " datasourceId         | gene2phenotype  \n",
      " effectDirection_down | 1               \n",
      " effectDirection_up   | 0               \n",
      " effectSize_down      | 0               \n",
      " effectSize_up        | 1               \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g2p = (\n",
    "    drop_null_columns(spark.read.parquet('/Users/irene/Documents/dev/pyspark/22.06.2/evidence/sourceId=gene2phenotype'))\n",
    "    .withColumn(\n",
    "        'effectDirection_down',\n",
    "        F.when(F.col('variantFunctionalConsequenceId') == 'SO_0002317', F.lit(True))\n",
    "    )\n",
    "    .withColumn('effectDirection_up', F.when(F.col('variantFunctionalConsequenceId') == 'SO_0002315', F.lit(True)))\n",
    "    .withColumn('effectSize_up', F.lit(True))\n",
    "    .withColumn('effectSize_down', F.lit(None))\n",
    "    .filter(F.col('effectDirection_up').isNotNull() | F.col('effectDirection_down').isNotNull())\n",
    "    .transform(aggregate_evidence)\n",
    "\n",
    ")\n",
    "\n",
    "g2p.show(2, False, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orphanet\n",
    "\n",
    "Directionality:\n",
    "- loss_of_function_variant: SO_0002054\n",
    "- gain_of_function_variant: SO_0002053"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------\n",
      " targetId             | ENSG00000130294 \n",
      " diseaseId            | MONDO_0019941   \n",
      " datasourceId         | orphanet        \n",
      " effectDirection_down | 1               \n",
      " effectDirection_up   | 0               \n",
      " effectSize_down      | 0               \n",
      " effectSize_up        | 1               \n",
      "-RECORD 1-------------------------------\n",
      " targetId             | ENSG00000143520 \n",
      " diseaseId            | MONDO_0014555   \n",
      " datasourceId         | orphanet        \n",
      " effectDirection_down | 1               \n",
      " effectDirection_up   | 0               \n",
      " effectSize_down      | 0               \n",
      " effectSize_up        | 1               \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orphanet = (\n",
    "    drop_null_columns(spark.read.parquet('/Users/irene/Documents/dev/pyspark/22.06.2/evidence/sourceId=orphanet'))\n",
    "    .withColumn(\n",
    "        'effectDirection_down',\n",
    "        F.when(F.col('variantFunctionalConsequenceId') == 'SO_0002054', F.lit(True))\n",
    "    )\n",
    "    .withColumn('effectDirection_up', F.when(F.col('variantFunctionalConsequenceId') == 'SO_0002053', F.lit(True)))\n",
    "    .withColumn('effectSize_up', F.lit(True))\n",
    "    .withColumn('effectSize_down', F.lit(None))\n",
    "    .filter(F.col('effectDirection_up').isNotNull() | F.col('effectDirection_down').isNotNull())\n",
    "    .transform(aggregate_evidence)\n",
    ")\n",
    "\n",
    "orphanet.show(2,False,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gene burden\n",
    "\n",
    "- Models that consider PTVs are always LoF\n",
    "- Effect size come from the betas/ORs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------\n",
      " targetId             | ENSG00000012048 \n",
      " diseaseId            | EFO_0000305     \n",
      " datasourceId         | gene_burden     \n",
      " effectDirection_down | 6               \n",
      " effectDirection_up   | 0               \n",
      " effectSize_down      | 1               \n",
      " effectSize_up        | 5               \n",
      "-RECORD 1-------------------------------\n",
      " targetId             | ENSG00000105610 \n",
      " diseaseId            | EFO_0004526     \n",
      " datasourceId         | gene_burden     \n",
      " effectDirection_down | 14              \n",
      " effectDirection_up   | 0               \n",
      " effectSize_down      | 14              \n",
      " effectSize_up        | 0               \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lof_models = [\n",
    "    'ptv5pcnt',\n",
    "    'ptv',\n",
    "    'ptvraredmg',\n",
    "    'pLoF',\n",
    "    'MLOF-VT',\n",
    "    'MLOF-MB',\n",
    "    'LOF-Burden',\n",
    "    'LOF-VT',\n",
    "    'ADD-WGR-FIRTH_M1.singleton',\n",
    "    'ADD-WGR-FIRTH_M1.01',\n",
    "    'ADD-WGR-FIRTH_M1.001',\n",
    "    'ADD-WGR-FIRTH_M1.1',\n",
    "    'ADD-WGR-FIRTH_M1.0001',\n",
    "]\n",
    "\n",
    "burden = (\n",
    "    drop_null_columns(spark.read.parquet('/Users/irene/Documents/dev/pyspark/22.06.2/evidence/sourceId=gene_burden'))\n",
    "    .filter(F.col('statisticalMethod').isin(lof_models))\n",
    "    .withColumn('effectDirection_down', F.lit(True))\n",
    "    .withColumn('effectDirection_up', F.lit(None))\n",
    "    .withColumn('effectSize_down', F.when((F.col('beta') < 0) | (F.col('oddsRatio') < 1), F.lit(True)))\n",
    "    .withColumn('effectSize_up', F.when((F.col('beta') > 0) | (F.col('oddsRatio') > 1), F.lit(True)))\n",
    "    .transform(aggregate_evidence)\n",
    ")\n",
    "\n",
    "burden.show(2, False, True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  GWAS of coding variants (Genetics)\n",
    "\n",
    "- Models that consider PTVs are always LoF\n",
    "- Effect size come from the betas/ORs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lof_consequences = [\n",
    "    'SO_0001589', # frameshift\n",
    "    'SO_0002012', # start_lost\n",
    "    'SO_0001587', # stop_gained\n",
    "    'SO_0001818', # protein altering variant\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0----------------------------------\n",
      " targetId             | ENSG00000205045    \n",
      " diseaseId            | EFO_0004833        \n",
      " datasourceId         | ot_genetics_portal \n",
      " effectDirection_down | 2                  \n",
      " effectDirection_up   | 0                  \n",
      " effectSize_down      | 2                  \n",
      " effectSize_up        | 0                  \n",
      "-RECORD 1----------------------------------\n",
      " targetId             | ENSG00000176920    \n",
      " diseaseId            | EFO_0005760        \n",
      " datasourceId         | ot_genetics_portal \n",
      " effectDirection_down | 1                  \n",
      " effectDirection_up   | 0                  \n",
      " effectSize_down      | 0                  \n",
      " effectSize_up        | 1                  \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ot_genetics = (\n",
    "    drop_null_columns(spark.read.parquet('/Users/irene/Documents/dev/pyspark/22.06.2/evidence/sourceId=ot_genetics_portal'))\n",
    "    .filter(F.col('variantFunctionalConsequenceId').isin(lof_consequences))\n",
    "    .withColumn('effectDirection_down', F.lit(True))\n",
    "    .withColumn('effectDirection_up', F.lit(None))\n",
    "    .withColumn('effectSize_down', F.when((F.col('beta') < 0) | (F.col('oddsRatio') < 1), F.lit(True)))\n",
    "    .withColumn('effectSize_up', F.when((F.col('beta') > 0) | (F.col('oddsRatio') > 1), F.lit(True)))\n",
    "    .transform(aggregate_evidence)\n",
    ")\n",
    "\n",
    "ot_genetics.show(2, False, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ClinVar\n",
    "\n",
    "- LoF variants are considered\n",
    "- Clinical significance addresses the size of the effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "significances = [\n",
    "    'pathogenic',\n",
    "    'likely pathogenic',\n",
    "    'risk factor',\n",
    "    'protective',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------\n",
      " targetId             | ENSG00000018236 \n",
      " diseaseId            | MONDO_0012929   \n",
      " datasourceId         | clinvar         \n",
      " effectDirection_down | 9               \n",
      " effectDirection_up   | 0               \n",
      " effectSize_down      | 0               \n",
      " effectSize_up        | 9               \n",
      "-RECORD 1-------------------------------\n",
      " targetId             | ENSG00000049860 \n",
      " diseaseId            | MONDO_0010006   \n",
      " datasourceId         | clinvar         \n",
      " effectDirection_down | 79              \n",
      " effectDirection_up   | 0               \n",
      " effectSize_down      | 0               \n",
      " effectSize_up        | 79              \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clinvar = (\n",
    "    drop_null_columns(spark.read.parquet('/Users/irene/Documents/dev/pyspark/22.06.2/evidence/sourceId=eva*'))\n",
    "    .withColumn('datasourceId', F.lit('clinvar'))\n",
    "    .withColumn('significance', F.explode('clinicalSignificances'))\n",
    "    .filter(F.col('significance').isin(significances))\n",
    "    .filter(F.col('variantFunctionalConsequenceId').isin(lof_consequences))\n",
    "    .withColumn('effectDirection_down', F.lit(True))\n",
    "    .withColumn('effectDirection_up', F.lit(None))\n",
    "    .withColumn('effectSize_down', F.when(F.col('significance') == 'protective', F.lit(True)))\n",
    "    .withColumn('effectSize_up', F.when(F.col('significance') != 'protective', F.lit(True)))\n",
    "    .transform(aggregate_evidence)\n",
    ")\n",
    "\n",
    "clinvar.show(2, False, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mouse models\n",
    "\n",
    "All the genotypes refer to KO models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------\n",
      " targetId             | ENSG00000001461 \n",
      " diseaseId            | EFO_1001451     \n",
      " datasourceId         | impc            \n",
      " effectDirection_down | 1               \n",
      " effectDirection_up   | 0               \n",
      " effectSize_down      | 0               \n",
      " effectSize_up        | 1               \n",
      "-RECORD 1-------------------------------\n",
      " targetId             | ENSG00000001617 \n",
      " diseaseId            | MONDO_0009141   \n",
      " datasourceId         | impc            \n",
      " effectDirection_down | 1               \n",
      " effectDirection_up   | 0               \n",
      " effectSize_down      | 0               \n",
      " effectSize_up        | 1               \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "impc = (\n",
    "    drop_null_columns(spark.read.parquet('/Users/irene/Documents/dev/pyspark/22.06.2/evidence/sourceId=impc'))\n",
    "    .withColumn('effectDirection_down', F.lit(True))\n",
    "    .withColumn('effectDirection_up', F.lit(None))\n",
    "    .withColumn('effectSize_up', F.lit(True))\n",
    "    .withColumn('effectSize_down', F.lit(None))\n",
    "    .transform(aggregate_evidence)\n",
    ")\n",
    "\n",
    "impc.show(2, False, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differential expression\n",
    "\n",
    "- All experiments are disease vs control\n",
    "    - Positive fold change: increase of expression\n",
    "    - Negative fold change: decrease of expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0--------------------------------\n",
      " targetId             | ENSG00000003137  \n",
      " diseaseId            | EFO_0003096      \n",
      " datasourceId         | expression_atlas \n",
      " effectDirection_down | 1                \n",
      " effectDirection_up   | 0                \n",
      " effectSize_down      | 0                \n",
      " effectSize_up        | 1                \n",
      "-RECORD 1--------------------------------\n",
      " targetId             | ENSG00000004777  \n",
      " diseaseId            | EFO_0000676      \n",
      " datasourceId         | expression_atlas \n",
      " effectDirection_down | 1                \n",
      " effectDirection_up   | 0                \n",
      " effectSize_down      | 0                \n",
      " effectSize_up        | 1                \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "expression = (\n",
    "    drop_null_columns(spark.read.parquet('/Users/irene/Documents/dev/pyspark/22.06.2/evidence/sourceId=expression_atlas'))\n",
    "    .withColumn('effectDirection_down', F.when(F.col('log2FoldChangeValue') < 0, F.lit(True)))\n",
    "    .withColumn('effectDirection_up', F.when(F.col('log2FoldChangeValue') > 0, F.lit(True)))\n",
    "    .withColumn('effectSize_down', F.lit(None))\n",
    "    .withColumn('effectSize_up', F.lit(True))\n",
    "    .transform(aggregate_evidence)\n",
    ")\n",
    "\n",
    "expression.show(2, False, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Score\n",
    "\n",
    "Synthetic lethality -> all LoF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------\n",
      " targetId             | ENSG00000166595 \n",
      " diseaseId            | EFO_0001378     \n",
      " datasourceId         | crispr          \n",
      " effectDirection_down | 1               \n",
      " effectDirection_up   | 0               \n",
      " effectSize_down      | 0               \n",
      " effectSize_up        | 1               \n",
      "-RECORD 1-------------------------------\n",
      " targetId             | ENSG00000197713 \n",
      " diseaseId            | EFO_0001075     \n",
      " datasourceId         | crispr          \n",
      " effectDirection_down | 1               \n",
      " effectDirection_up   | 0               \n",
      " effectSize_down      | 0               \n",
      " effectSize_up        | 1               \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crispr = (\n",
    "    drop_null_columns(spark.read.parquet('/Users/irene/Documents/dev/pyspark/22.06.2/evidence/sourceId=crispr'))\n",
    "    .withColumn('effectDirection_down', F.lit(True))\n",
    "    .withColumn('effectDirection_up', F.lit(None))\n",
    "    .withColumn('effectSize_up', F.lit(True))\n",
    "    .withColumn('effectSize_down', F.lit(None))\n",
    "    .transform(aggregate_evidence)\n",
    ")\n",
    "\n",
    "crispr.show(2, False, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    chembl,\n",
    "    g2p,\n",
    "    orphanet,\n",
    "    burden,\n",
    "    ot_genetics,\n",
    "    clinvar,\n",
    "    impc,\n",
    "    expression,\n",
    "    crispr,\n",
    "    # oncology,\n",
    "    # coloc,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = reduce(DataFrame.unionByName, datasets).repartition(20).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "cwd = Path.cwd().parent\n",
    "\n",
    "# all_data.write.parquet(str(cwd / 'outputs' / 'data_harmonisation'), mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATS for chembl\n",
      "... 70211 total associations.\n",
      "... 4982 associations with discrepant direction (7.10%).\n",
      "... 0 associations with discrepant size (0.00%). \n",
      "\n",
      "STATS for gene2phenotype\n",
      "... 2425 total associations.\n",
      "... 0 associations with discrepant direction (0.00%).\n",
      "... 0 associations with discrepant size (0.00%). \n",
      "\n",
      "STATS for orphanet\n",
      "... 1757 total associations.\n",
      "... 0 associations with discrepant direction (0.00%).\n",
      "... 0 associations with discrepant size (0.00%). \n",
      "\n",
      "STATS for gene_burden\n",
      "... 2874 total associations.\n",
      "... 0 associations with discrepant direction (0.00%).\n",
      "... 144 associations with discrepant size (5.01%). \n",
      "\n",
      "STATS for ot_genetics_portal\n",
      "... 114 total associations.\n",
      "... 0 associations with discrepant direction (0.00%).\n",
      "... 3 associations with discrepant size (2.63%). \n",
      "\n",
      "STATS for clinvar\n",
      "... 10275 total associations.\n",
      "... 0 associations with discrepant direction (0.00%).\n",
      "... 1 associations with discrepant size (0.01%). \n",
      "\n",
      "STATS for impc\n",
      "... 523293 total associations.\n",
      "... 0 associations with discrepant direction (0.00%).\n",
      "... 0 associations with discrepant size (0.00%). \n",
      "\n",
      "STATS for expression_atlas\n",
      "... 161620 total associations.\n",
      "... 2578 associations with discrepant direction (1.60%).\n",
      "... 0 associations with discrepant size (0.00%). \n",
      "\n",
      "STATS for crispr\n",
      "... 1846 total associations.\n",
      "... 0 associations with discrepant direction (0.00%).\n",
      "... 0 associations with discrepant size (0.00%). \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Per datasource\n",
    "\n",
    "[get_stats(e) for e in datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATS for all\n",
      "... 767340 total associations.\n",
      "... 9102 associations with discrepant direction (1.19%).\n",
      "... 172 associations with discrepant size (0.02%). \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# All\n",
    "\n",
    "get_stats(all_data, all=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provided examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDLR/low density lipoprotein cholesterol measurement\n",
    "\n",
    "LDLR down - low density lipoprotein cholesterol measurement up ->  Wrong therapeutic hypothesis for inhibitor\n",
    "\n",
    "- We only have data from gene_burden because variants from Genetics Portal are not eligible\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------+------------+--------------------+------------------+---------------+-------------+\n",
      "|       targetId|  diseaseId|datasourceId|effectDirection_down|effectDirection_up|effectSize_down|effectSize_up|\n",
      "+---------------+-----------+------------+--------------------+------------------+---------------+-------------+\n",
      "|ENSG00000130164|EFO_0004611| gene_burden|                   4|                 0|              0|            4|\n",
      "+---------------+-----------+------------+--------------------+------------------+---------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    all_data\n",
    "    .filter((F.col('diseaseId') == 'EFO_0004611') & (F.col('targetId') == 'ENSG00000130164'))\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCSK9/low density lipoprotein cholesterol measurement\n",
    "\n",
    "PCSK9 down - low density lipoprotein cholesterol measurement down -> Good therapeutic hypothesis for inhibitor\n",
    "- We only have data from gene_burden because variants from Genetics Portal are not eligible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------+------------+--------------------+------------------+---------------+-------------+\n",
      "|       targetId|  diseaseId|datasourceId|effectDirection_down|effectDirection_up|effectSize_down|effectSize_up|\n",
      "+---------------+-----------+------------+--------------------+------------------+---------------+-------------+\n",
      "|ENSG00000169174|EFO_0004611| gene_burden|                  11|                 0|             11|            0|\n",
      "+---------------+-----------+------------+--------------------+------------------+---------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    all_data\n",
    "    .filter((F.col('diseaseId') == 'EFO_0004611') & (F.col('targetId') == 'ENSG00000169174'))\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FLG/atopic eczema\n",
    "\n",
    "FLG down - atopic eczema up -> Wrong therapeutic hypothesis for inhibitor. Benchmark with expression.\n",
    "- All the sources in the Platform populate the analysis\n",
    "- Practically all available evidence support the hypothesis\n",
    "- There is one evidence from the genetics_portal that is discordant (1_152313385_G_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------+------------------+--------------------+------------------+---------------+-------------+\n",
      "|       targetId|  diseaseId|      datasourceId|effectDirection_down|effectDirection_up|effectSize_down|effectSize_up|\n",
      "+---------------+-----------+------------------+--------------------+------------------+---------------+-------------+\n",
      "|ENSG00000143631|EFO_0000274|           clinvar|                  12|                 0|              0|           12|\n",
      "|ENSG00000143631|EFO_0000274|              impc|                   2|                 0|              0|            2|\n",
      "|ENSG00000143631|EFO_0000274|ot_genetics_portal|                   6|                 0|              1|            5|\n",
      "|ENSG00000143631|EFO_0000274|  expression_atlas|                   2|                 0|              0|            2|\n",
      "|ENSG00000143631|EFO_0000274|       gene_burden|                   8|                 0|              0|            8|\n",
      "+---------------+-----------+------------------+--------------------+------------------+---------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    all_data\n",
    "    .filter((F.col('diseaseId') == 'EFO_0000274') & (F.col('targetId') == 'ENSG00000143631'))\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IL4R/atopic eczema\n",
    "\n",
    "IL4R up - atopic eczema up -> Good therapeutic hypothesis for inhibitor\n",
    "- IMPC evidence is not present because the disease is not the same (associations have not been expanded)\n",
    "- ClinVar evidence is not present because variants are not eligible\n",
    "- ChEMBL and Expression Atlas are consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------+----------------+--------------------+------------------+---------------+-------------+\n",
      "|       targetId|  diseaseId|    datasourceId|effectDirection_down|effectDirection_up|effectSize_down|effectSize_up|\n",
      "+---------------+-----------+----------------+--------------------+------------------+---------------+-------------+\n",
      "|ENSG00000077238|EFO_0000274|          chembl|                   0|                36|              0|           36|\n",
      "|ENSG00000077238|EFO_0000274|expression_atlas|                   0|                 1|              0|            1|\n",
      "+---------------+-----------+----------------+--------------------+------------------+---------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    all_data\n",
    "    .filter((F.col('diseaseId') == 'EFO_0000274') & (F.col('targetId') == 'ENSG00000077238'))\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f4b6dc36c032161cfa2dcc93f31fcb0bfb11bc6fea6f0772b15a0710e4778680"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
